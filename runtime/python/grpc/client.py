import grpc
import cosyvoice_pb2
import cosyvoice_pb2_grpc
import sounddevice as sd
import numpy as np
import os
import torchaudio

# æœåŠ¡å™¨åœ°å€ï¼ˆä¿®æ”¹ä¸ºå®é™… IPï¼‰
SERVER_ADDRESS = "20.108.25.156:50000"

# é‡‡æ ·ç‡
SAMPLE_RATE = 24000

def load_wav(wav, target_sr):
    speech, sample_rate = torchaudio.load(wav, backend='soundfile')
    speech = speech.mean(dim=0, keepdim=True)
    if sample_rate != target_sr:
        assert sample_rate > target_sr, 'wav sample rate {} must be greater than {}'.format(sample_rate, target_sr)
        speech = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)(speech)
    return speech

def play_audio_stream(response):
    """æ¥æ”¶æœåŠ¡å™¨è¿”å›çš„éŸ³é¢‘æµï¼Œå¹¶å®æ—¶æ’­æ”¾"""
    audio_buffer = bytearray()
    
    for res in response:  # âœ… è¿­ä»£ gRPC æµ
        audio_buffer.extend(res.tts_audio)  # è¿½åŠ éŸ³é¢‘æ•°æ®
    
    if len(audio_buffer) > 0:
        audio_array = np.frombuffer(audio_buffer, dtype=np.int16)
        sd.play(audio_array, samplerate=SAMPLE_RATE)
        sd.wait()

def send_request(mode):
    """å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨ï¼Œå¹¶æ’­æ”¾å’Œä¿å­˜è¿”å›çš„ TTS éŸ³é¢‘"""
    channel = grpc.insecure_channel(SERVER_ADDRESS)
    stub = cosyvoice_pb2_grpc.CosyVoiceStub(channel)

    while True:
        text = input("\nè¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬ (è¾“å…¥ 'exit' é€€å‡º): ").strip()
        if text.lower() == "exit":
            break
        

        if mode == "zero_shot":
            request = cosyvoice_pb2.Request(
                zero_shot_request=cosyvoice_pb2.zeroshotRequest(tts_text=text)
            )
        elif mode == "cross_lingual":
            request = cosyvoice_pb2.Request(
                cross_lingual_request=cosyvoice_pb2.crosslingualRequest(tts_text=text)
            )
        elif mode == "instruct":
            instruct_text = input("è¯·è¾“å…¥æŒ‡ä»¤æ–‡æœ¬ (e.g., 'ç”¨å››å·è¯è¯´è¿™å¥è¯'): ").strip()
            request = cosyvoice_pb2.Request(
                instruct_request=cosyvoice_pb2.instructRequest(tts_text=text,instruct_text=instruct_text)
            )
        elif mode == "voice_change":
            prompt_text = input("è¯·è¾“å…¥æ–°äººå£°å¯¹åº”æ–‡å­—ç”¨äºæ¨¡å‹è®­ç»ƒçŸ«æ­£: ").strip()
            # è®©ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ `.wav` æ–‡ä»¶
            prompt_wav_path = input("è¯·è¾“å…¥è¦ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘æ–‡ä»¶ (åŒç›®å½•ä¸‹çš„ .wav æ–‡ä»¶å): ").strip()
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(prompt_wav_path):
                print(f"âŒ æ–‡ä»¶ {prompt_wav_path} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
                return
            print("å³å°†ä¸Šä¼ çš„prompt_textæ˜¯"+prompt_text)
            # è¯»å– .wav æ–‡ä»¶
            prompt_speech = load_wav(prompt_wav_path, 16000)

            print(f"ã€DEBUGã€‘å³å°†å‘é€çš„ prompt_text = {repr(prompt_text)}, é•¿åº¦ = {len(prompt_text)}")

            request = cosyvoice_pb2.Request(
                voice_change_request=cosyvoice_pb2.voicechangeRequest(
                    prompt_text=prompt_text,
                    prompt_audio=(prompt_speech.numpy() * (2**15)).astype(np.int16).tobytes()
                )
            )
            print(f"ã€DEBUGã€‘prompt_audio é•¿åº¦ = {len(request.voice_change_request.prompt_audio)} å­—èŠ‚")
            
            print("\nğŸš€ æ­£åœ¨ä¸Šä¼ æ–°çš„ prompt_text å’Œ prompt_audio...")
            response = stub.VoiceChange(request)
            for _ in response:
                print("âœ… æœåŠ¡å™¨å·²æˆåŠŸæ›´æ–°æ–°çš„äººå£°ï¼")

            return  # ğŸ”´ ç›´æ¥è¿”å›ï¼Œä¸è¦ç»§ç»­æ‰§è¡Œ `Inference()`

        else:
            print("æ¨¡å¼é”™è¯¯ï¼")
            return

        print("\nğŸ™ï¸ æœåŠ¡å™¨å¤„ç†ä¸­...")
        
        # æ’­æ”¾å¹¶ä¿å­˜éŸ³é¢‘
        response = stub.Inference(request)

        play_audio_stream(response)  # âœ… è¿™æ ·æ‰æ˜¯æ­£ç¡®çš„

        

if __name__ == "__main__":
    print("\nè¯·é€‰æ‹©æ¨¡å¼: ")
    print("1 Zero-shot (ç”¨æ–‡æœ¬åŒ¹é…éŸ³è‰²)")
    print("2 Cross-lingual (è·¨è¯­è¨€)")
    print("3 Instruct (æŒ‡å®šé£æ ¼/å£éŸ³)")
    print("4 VoiceChange")

    mode_map = {"1": "zero_shot", "2": "cross_lingual", "3": "instruct", "4": "voice_change"}
    mode = input("\nè¯·è¾“å…¥æ¨¡å¼ç¼–å·: ").strip()
    mode = mode_map.get(mode)

    if mode:
        send_request(mode)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œç¨‹åºé€€å‡ºï¼")